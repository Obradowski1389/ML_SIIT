{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(993, 10)\n",
      "(951, 10)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('data/train.tsv', sep='\\t')\n",
    "test = pd.read_csv('data/test.tsv', sep='\\t')\n",
    "\n",
    "df = pd.concat([train, test], axis=0)\n",
    "\n",
    "# removing cars with year of production less than 1900\n",
    "train = train[train['Godina proizvodnje'] >= 1900]\n",
    "print(train.shape)\n",
    "\n",
    "#removing duplicates\n",
    "train.drop_duplicates(inplace=True)\n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "nominal = {\n",
    "    'Karoserija': df['Karoserija'].unique(),\n",
    "    'Gorivo': df['Gorivo'].unique(),\n",
    "    # 'Grad': df['Grad'].unique(),\n",
    "    'Marka': df['Marka'].unique()\n",
    "}\n",
    "\n",
    "def encode(binary, nominal=nominal):\n",
    "    # label encoding for binary\n",
    "    for col in binary:\n",
    "        train[col] = train[col].map({'Manuelni': 0, 'Automatski': 1})\n",
    "        test[col] = test[col].map({'Manuelni': 0, 'Automatski': 1})\n",
    "    # one hot encoding for nominal\n",
    "    for col in nominal:\n",
    "        for category in nominal[col]:\n",
    "            train[category] = (train[col] == category).astype(int)\n",
    "            test[category] = (test[col] == category).astype(int)\n",
    "        train.drop(col, axis=1, inplace=True)\n",
    "        test.drop(col, axis=1, inplace=True)\n",
    "\n",
    "    return train, test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = encode(['Menjac'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_price, std_price = 0, 0\n",
    "\n",
    "def normalize_features(num_vars):\n",
    "    for col in num_vars:            \n",
    "        mean = train[col].mean()\n",
    "        std = train[col].std()\n",
    "        if col == 'Cena':\n",
    "            global mean_price, std_price\n",
    "            mean_price, std_price = mean, std\n",
    "        train[col] = (train[col] - mean) / std\n",
    "        test[col] = (test[col] - mean) / std\n",
    "\n",
    "    return train, test\n",
    "\n",
    "train, test = normalize_features(['Godina proizvodnje', 'Zapremina motora', 'Kilometraza', 'Konjske snage', 'Cena'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(x_train, y_train, LR=0.21, ALPHA=0.3, EPOCHS=9000):\n",
    "    # Lasso\n",
    "    rows, columns = x_train.shape\n",
    "    coefficients = np.zeros(columns)\n",
    "    for _ in range(EPOCHS):\n",
    "        y_pred = np.dot(x_train, coefficients)\n",
    "        error = y_pred - y_train\n",
    "        gradients = (1 / rows) * np.dot(x_train.T, error) + ALPHA * np.sign(coefficients)\n",
    "        coefficients -= LR * gradients\n",
    "    return coefficients\n",
    "\n",
    "\n",
    "# def predict(x_test, coefficients):\n",
    "#     return np.dot(x_test, coefficients)\n",
    "\n",
    "def calculate_rmse(y_true, y_pred):\n",
    "    residuals = y_true - y_pred\n",
    "    squared_residuals = residuals ** 2\n",
    "    mean_squared_residuals = squared_residuals.mean()\n",
    "    rmse = np.sqrt(mean_squared_residuals)\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNNRegressor:\n",
    "    def __init__(self, k, dist):\n",
    "        self.k = k\n",
    "        self.distance = dist\n",
    "        self.X_train = []\n",
    "        self.y_train = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        predictions = []\n",
    "        for sample in X_test:\n",
    "            distances = np.array([self.distance(sample, x) for x in self.X_train])\n",
    "            nearest_indices = np.argsort(distances)[:self.k]\n",
    "            nearest_labels = [self.y_train[i] for i in nearest_indices] \n",
    "            prediction = np.mean(nearest_labels)\n",
    "            predictions.append(prediction)\n",
    "        return np.array(predictions)\n",
    "    \n",
    "    @staticmethod\n",
    "    def euclidean_distance(x, y):\n",
    "        sum_squared_diff = 0.0\n",
    "\n",
    "        for i in range(len(x)):\n",
    "            sum_squared_diff += (x[i] - y[i]) ** 2\n",
    "\n",
    "        return sum_squared_diff ** 0.5\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def loss(y,y_predicted):\n",
    "#     n=len(y)\n",
    "#     s=0\n",
    "#     for i in range(n):\n",
    "#         s+=(y[i]-y_predicted[i])**2\n",
    "#     return (1/n)*s\n",
    "\n",
    "# def fit_with_regularization(X, y, learning_rate=0.1, max_iterations=10000, lambda_=0.1):\n",
    "#     weights = np.zeros(X.shape[1])\n",
    "#     bias = 0\n",
    "#     loss = []\n",
    "\n",
    "#     for _ in range(max_iterations):\n",
    "#         y_hat = np.dot(X, weights) + bias\n",
    "#         loss.append(calculate_rmse(y, y_hat))\n",
    "\n",
    "#         partial_w = (1 / X.shape[0]) * (2 * np.dot(X.T, (y_hat - y)))\n",
    "#         partial_b = (1 / X.shape[0]) * (2 * np.sum(y_hat - y))\n",
    "\n",
    "#         # L1 regularization\n",
    "#         regularization_term = lambda_ * weights\n",
    "#         partial_w += regularization_term\n",
    "\n",
    "#         weights -= learning_rate * partial_w\n",
    "#         bias -= learning_rate * partial_b\n",
    "\n",
    "#     return weights, bias, loss\n",
    "\n",
    "# def predict(X, w, bias):\n",
    "#     return np.dot(X, w) + bias\n",
    "\n",
    "class LinearRegression:\n",
    "  \n",
    "  ## Set the learning rate and number of iterations\n",
    "  def __init__(self,learning_rate=0.01,n_iters=1000, lambda_=0.1):\n",
    "    # initialize learning rate lr and number of iteration iters\n",
    "    self.lr=learning_rate\n",
    "    self.iters=n_iters\n",
    "    self.lambda_=lambda_\n",
    "    # initialize the weights matrix\n",
    "    self.weights=None\n",
    "    \n",
    "  def fit(self,X,y):\n",
    "    n_samples=len(X)\n",
    "    # modify x, add 1 column with value 1\n",
    "    ones=np.ones(len(X))\n",
    "    features=np.c_[ones,X]\n",
    "    # initialize the weights matrix\n",
    "    self.weights = np.zeros(features.shape[1])\n",
    "\n",
    "    for i in range(self.iters):\n",
    "      # predicted labels\n",
    "      y_predicted=np.dot(features,self.weights.T)\n",
    "      # calculate the error\n",
    "      error=y_predicted-y\n",
    "      # compute the partial derivated of the cost function\n",
    "      dw = (2 / n_samples) * np.dot(features.T,error)\n",
    "      # update the weights matrix\n",
    "      regularization_term = (self.lambda_ / n_samples) * np.sign(self.weights)\n",
    "# Update the weights matrix with regularization\n",
    "      self.weights -= self.lr * (dw + regularization_term)\n",
    "       \n",
    "  def predict(self,X):\n",
    "    ones=np.ones(len(X))\n",
    "    features=np.c_[ones,X]\n",
    "    # predict the labels matrix\n",
    "    y_predicted=np.dot(features,self.weights.T)\n",
    "    return y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(columns= ['Cena', 'Grad'], axis=1)\n",
    "y_train = train['Cena']\n",
    "X_test = test.drop(columns= ['Cena', 'Grad'], axis=1)\n",
    "y_test = test['Cena']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coeff = fit(X_train, y_train)\n",
    "# y_pred = predict(X_test, coeff)\n",
    "\n",
    "# print(calculate_rmse(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for i in range(1, 30):\n",
    "#     knn = KNNRegressor(k=i, dist=KNNRegressor.euclidean_distance)\n",
    "#     knn.fit(X_train.values, y_train.values)\n",
    "#     y_pred = knn.predict(X_test.values)\n",
    "#     print(f' k={i}: {calculate_rmse(y_test, y_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185924.2925204386\n"
     ]
    }
   ],
   "source": [
    "# w, b, loss = fit_with_regularization(X_train, y_train)\n",
    "# y_pred = predict(X_test, w, b)\n",
    "\n",
    "# print(calculate_rmse(y_test, y_pred))\n",
    "\n",
    "# plt.plot(range(len(loss)), loss)\n",
    "# plt.show()\n",
    "\n",
    "c=LinearRegression(learning_rate=0.01, n_iters=10000)\n",
    "c.fit(X_train, y_train)\n",
    "y_pred=c.predict(X_test)\n",
    "\n",
    "y_pred = y_pred * std_price + mean_price\n",
    "y_test = y_test * std_price + mean_price\n",
    "\n",
    "print(calculate_rmse(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
